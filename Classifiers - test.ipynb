{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_title</th>\n",
       "      <th>title_year</th>\n",
       "      <th>director_name</th>\n",
       "      <th>gross</th>\n",
       "      <th>budget</th>\n",
       "      <th>content_rating</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Avatar</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>James Cameron</td>\n",
       "      <td>760505847.0</td>\n",
       "      <td>237000000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pirates of the Caribbean: At World's End</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>Gore Verbinski</td>\n",
       "      <td>309404152.0</td>\n",
       "      <td>300000000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spectre</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>Sam Mendes</td>\n",
       "      <td>200074175.0</td>\n",
       "      <td>245000000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Dark Knight Rises</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>Christopher Nolan</td>\n",
       "      <td>448130642.0</td>\n",
       "      <td>250000000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>John Carter</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>Andrew Stanton</td>\n",
       "      <td>73058679.0</td>\n",
       "      <td>263700000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 movie_title  title_year      director_name  \\\n",
       "0                                    Avatar       2009.0      James Cameron   \n",
       "1  Pirates of the Caribbean: At World's End       2007.0     Gore Verbinski   \n",
       "2                                   Spectre       2015.0         Sam Mendes   \n",
       "3                     The Dark Knight Rises       2012.0  Christopher Nolan   \n",
       "4                               John Carter       2012.0     Andrew Stanton   \n",
       "\n",
       "         gross       budget  content_rating  language  \n",
       "0  760505847.0  237000000.0               3         9  \n",
       "1  309404152.0  300000000.0               3         9  \n",
       "2  200074175.0  245000000.0               3         9  \n",
       "3  448130642.0  250000000.0               3         9  \n",
       "4   73058679.0  263700000.0               3         9  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load imdb csv file into dataframe\n",
    "imdb = pd.read_csv(\"./labels_adjusted_metadata.csv\" )\n",
    "imdb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Using content rating, budget & language to predict gross earnings\n",
    "X = imdb.loc[:, ['content_rating','budget', 'language']].values \n",
    "y = imdb.loc[:, 'gross'].values \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression\n",
      "[  1.06757722e+08   4.09151495e+07   4.09151495e+07 ...,   5.73757926e+07\n",
      "   1.87349829e+06   4.09151495e+07]\n",
      "0.0704271198834\n",
      "SVR\n",
      "[ 30224284.77905821  30224141.13795232  30224141.13795232 ...,\n",
      "  30224392.0000009   30224253.26184049  30224141.13795232]\n",
      "-0.104044628409\n",
      "LogisticRegression\n",
      "[  9.25402000e+05   2.18051260e+08   2.18051260e+08 ...,   5.77351900e+06\n",
      "   6.38951000e+05   2.18051260e+08]\n",
      "0.0\n",
      "DecisionTreeClassifier\n",
      "[ 8000000.   403932.   403932. ...,  5773519.  1196752.   403932.]\n",
      "0.000883392226148\n",
      "KNeighborsClassifier\n",
      "[ 3000000.    22000.    22000. ...,   866778.   252652.    22000.]\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/livfranzen/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:455: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearDiscriminantAnalysis\n",
      "[ 8000000.   403932.   403932. ...,  5773519.  1196752.   403932.]\n",
      "0.000883392226148\n",
      "GaussianNB\n",
      "[ 8000000.   403932.   403932. ...,  5773519.  1196752.   403932.]\n",
      "0.000883392226148\n",
      "SVC\n",
      "[  8.00000000e+06   1.19412921e+08   1.19412921e+08 ...,   2.18051260e+08\n",
      "   1.19675200e+06   1.19412921e+08]\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "#testing a range of classifiers.. \n",
    "from sklearn                        import metrics, svm\n",
    "from sklearn.linear_model           import LinearRegression\n",
    "from sklearn.linear_model           import LogisticRegression\n",
    "from sklearn.tree                   import DecisionTreeClassifier\n",
    "from sklearn.neighbors              import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis  import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes            import GaussianNB\n",
    "from sklearn.svm                    import SVC\n",
    "\n",
    "trainingData    = X_train\n",
    "trainingScores  = y_train \n",
    "predictionData  = X_test \n",
    "predictionScores = y_test\n",
    "\n",
    "clf = LinearRegression()\n",
    "clf.fit(trainingData, trainingScores)\n",
    "print(\"LinearRegression\")\n",
    "print(clf.predict(predictionData))\n",
    "print(clf.score(predictionData, predictionScores))\n",
    "\n",
    "clf = svm.SVR()\n",
    "clf.fit(trainingData, trainingScores)\n",
    "print(\"SVR\")\n",
    "print(clf.predict(predictionData))\n",
    "print(clf.score(predictionData, predictionScores))\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(trainingData, trainingScores)\n",
    "print(\"LogisticRegression\")\n",
    "print(clf.predict(predictionData))\n",
    "print(clf.score(predictionData, predictionScores))\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(trainingData, trainingScores)\n",
    "print(\"DecisionTreeClassifier\")\n",
    "print(clf.predict(predictionData))\n",
    "print(clf.score(predictionData, predictionScores))\n",
    "\n",
    "clf = KNeighborsClassifier()\n",
    "clf.fit(trainingData, trainingScores)\n",
    "print(\"KNeighborsClassifier\")\n",
    "print(clf.predict(predictionData))\n",
    "print(clf.score(predictionData, predictionScores))\n",
    "\n",
    "clf = LinearDiscriminantAnalysis()\n",
    "clf.fit(trainingData, trainingScores)\n",
    "print(\"LinearDiscriminantAnalysis\")\n",
    "print(clf.predict(predictionData))\n",
    "print(clf.score(predictionData, predictionScores))\n",
    "\n",
    "clf = GaussianNB()\n",
    "clf.fit(trainingData, trainingScores)\n",
    "print(\"GaussianNB\")\n",
    "print(clf.predict(predictionData))\n",
    "print(clf.score(predictionData, predictionScores))\n",
    "\n",
    "clf = SVC()\n",
    "clf.fit(trainingData, trainingScores)\n",
    "print(\"SVC\")\n",
    "print(clf.predict(predictionData))\n",
    "print(clf.score(predictionData, predictionScores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.00491683e+08,   1.49462290e+07,   2.30313900e+07, ...,\n",
       "         1.43346450e+07,   3.13436000e+05,   1.62000000e+02])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the real gross data\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
